{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## USed for merging the 15 attraction dataset containing waiting times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "%pip install openpyxl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge files on Attraction -> output: Each excel for each attraction with cols ('Datetime', 'WaitTime', 'Month', 'Year')\n",
    "### 0Attraction open\n",
    "### -1Virtual Queue\n",
    "### -2Maintenance\n",
    "###  -3Closed due to weather\n",
    "### -4Attraction closed\n",
    "### 91over 90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Folder with the Excel files\n",
    "folder_path = \"/home/ms/hfu/ML/ML_Presentation_Workspace/EU_PARK/europark_raw_files\" # Corrected absolute path\n",
    "\n",
    "# Regex to extract attraction, month, and year from filename\n",
    "pattern = r'^(.*?) - Queue times in (\\w+) (\\d{4})\\.xlsx'\n",
    "\n",
    "# Dictionary to hold data for each attraction\n",
    "attraction_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            attraction = match.group(1).strip()\n",
    "            month = match.group(2)\n",
    "            year = int(match.group(3))\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the file\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "            # Add metadata\n",
    "            df['Month'] = month\n",
    "            df['Year'] = year\n",
    "\n",
    "            # Rename columns for consistency\n",
    "            df.columns = ['Datetime', 'WaitTime', 'Month', 'Year']\n",
    "\n",
    "            # Add to the attraction's list\n",
    "            if attraction not in attraction_data:\n",
    "                attraction_data[attraction] = []\n",
    "            attraction_data[attraction].append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attraction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each attraction, combine all months and save one Excel file\n",
    "safe_attraction_name_list = []\n",
    "save_path = '/home/ms/hfu/ML/ML_Presentation_Workspace/EU_PARK/europark_attraction_merged_dfs'\n",
    "for attraction, dfs in attraction_data.items():\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Drop rows where Datetime is missing\n",
    "    combined_df = combined_df.dropna(subset=['Datetime'])\n",
    "\n",
    "    # Split Datetime into Date and Time using string operations\n",
    "    combined_df[['Date', 'Time']] = combined_df['Datetime'].astype(str).str.strip().str.split(' ', expand=True)\n",
    "    safe_attraction_name = attraction.replace('-', ' ')  # avoid file path issues # Create the output file path\n",
    "    fil_safe_attraction_name = safe_attraction_name.replace(' ','_')\n",
    "    safe_attraction_name_list.append(fil_safe_attraction_name)\n",
    "    # print(safe_attraction_name_list)\n",
    "    output_file = os.path.join(save_path, f\"{fil_safe_attraction_name} - All Queue Times.xlsx\")\n",
    "    combined_df.to_excel(output_file, index=False)\n",
    "    print(f\"✅ Saved merged file for: {attraction} -> {output_file}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge All attractions in one single excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder where individual attraction Excel files are stored\n",
    "folder_path = 'EU_PARK/europark_attraction_merged_dfs/'\n",
    "\n",
    "# Get list of merged attraction files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('All Queue Times.xlsx')]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    # Full path to the Excel file\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    # Extract attraction name from filename\n",
    "    attraction = file.replace(' - All Queue Times.xlsx', '').strip()\n",
    "\n",
    "    # Read file\n",
    "    df = pd.read_excel(file_path)\n",
    "    df = df.drop(columns=['Datetime'], errors='ignore')\n",
    "    df.rename(columns={'WaitTime': f'{attraction}_WaitTime'}, inplace=True)\n",
    "\n",
    "    # Merge using pandas only\n",
    "    if merged_df is None:\n",
    "        merged_df = df\n",
    "    else:\n",
    "        merged_df = pd.merge(merged_df, df, on=['Date', 'Time', 'Month', 'Year'], how='outer')\n",
    "\n",
    "merged_df = merged_df.sort_values(by=['Date', 'Time'])\n",
    "\n",
    "output_file = os.path.join(folder_path, 'All_Attractions_Queue_Times_By_Date_Time.csv')\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Final merged file saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_dt = pd.read_csv(\"EU_PARK/europark_attraction_merged_dfs/All_Attractions_Queue_Times_By_Date_Time.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_dt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_dt.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_dt = merged_df_dt.dropna(subset=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_missing_values(df):\n",
    "    total_rows = len(df)\n",
    "    missing_count = df.isna().sum()\n",
    "    missing_percent = (missing_count / total_rows) * 100\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        'Missing Count': missing_count,\n",
    "        'Missing %': missing_percent.round(2)\n",
    "    })\n",
    "    result = result.sort_values(by='Missing %', ascending=False)\n",
    "\n",
    "    print(result)  # Only show columns with missing values\n",
    "\n",
    "report_missing_values(merged_df_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df_dt.to_csv(\"EU_PARK/All_Attractions_Queue_Times_By_Date_Time.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge wind data files to one excel files contating wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_fn_wind_prec_temp(df_path,df_type):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        df_path (str): Path to folder containing Excel files.\n",
    "        data_type (str): Type of data ('wind', 'prec', 'temp', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe with Month and Year columns.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(df_path) if f.endswith('.xlsx')]\n",
    "    data_final = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(df_path, file)\n",
    "\n",
    "        # Extract month and year from filename: 'Wind speed in March 2024.xlsx'\n",
    "        if df_type == 'wind':\n",
    "            name_parts = file.replace('.xlsx', '').replace('Wind speed in ', '').strip().split()\n",
    "        elif df_type == 'prec':\n",
    "            name_parts = file.replace('.xlsx', '').replace('Precipitation probability in ', '').strip().split()\n",
    "        elif df_type == 'temp':\n",
    "            name_parts = file.replace('.xlsx', '').replace('Temperatures in ', '').strip().split()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown data_type: {df_type}\")\n",
    "        month = name_parts[0]\n",
    "        year = name_parts[1]\n",
    "\n",
    "        # Read the file\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Add Month and Year columns\n",
    "        df['Month'] = month\n",
    "        df['Year'] = int(year)\n",
    "        data_final.append(df)\n",
    "\n",
    "    # Combine all dataframes into one\n",
    "    wind_df = pd.concat(data_final, ignore_index=True)\n",
    "    wind_df[['Date', 'Time']] = wind_df['date_time'].astype(str).str.strip().str.split(' ', expand=True)\n",
    "    wind_df = wind_df.drop(columns=['date_time'])\n",
    "\n",
    "    return wind_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_loc = 'EU_PARK/wind_speed/'\n",
    "final_wind_df = merge_fn_wind_prec_temp(wind_loc,df_type='wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_wind_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_wind_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(final_wind_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Precipitation data files to one excel files contating Precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation_loc = '/home/ms/hfu/ML/ML_Presentation_Workspace/EU_PARK/Precipitation/'\n",
    "\n",
    "if not os.path.exists(precipitation_loc):\n",
    "\traise FileNotFoundError(f\"Directory does not exist: {precipitation_loc}\")\n",
    "\n",
    "final_prec_df = merge_fn_wind_prec_temp(precipitation_loc,df_type='prec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prec_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(final_prec_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Temperature data files to one excel files contating Temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_loc = 'EU_PARK/Temperatures/'\n",
    "final_temp_df = merge_fn_wind_prec_temp(temperature_loc,df_type='temp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(final_temp_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Final Excel of waiting times with wind data, Precipitaiton and Temperature data based on Month ,year,Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_dt : final df for all attraction waiting times\n",
    "# final_temp_df: final df for all attraction Temperatures\n",
    "# final_prec_df: final df for all attraction Precipitation\n",
    "# final_wind_df: final df for all attraction Wind speed in kmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_keys = ['Month', 'Year', 'Date', 'Time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step outer merges using pandas only\n",
    "merged = pd.merge(merged_df_dt, final_temp_df, on=['Month', 'Year', 'Date', 'Time'], how='outer')\n",
    "merged = pd.merge(merged, final_prec_df, on=['Month', 'Year', 'Date', 'Time'], how='outer')\n",
    "merged = pd.merge(merged, final_wind_df, on=['Month', 'Year', 'Date', 'Time'], how='outer')\n",
    "\n",
    "# Optional: sort for clean structure\n",
    "final_merged = merged.sort_values(by=['Year', 'Month', 'Date', 'Time']).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(final_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = final_merged.groupby(['Month', 'Year', 'ARTHUR_WaitTime']).agg(lambda x: x.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column for school holiday = 0 or 1 (true or false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holiday_df = pd.read_csv('/home/ms/hfu/ML/ML_Presentation_Workspace/EU_PARK/holidays/baden_wuerttemberg_school_holidays_2022_2026.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holiday_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holiday_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holiday_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge school holidays into final_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Convert both Date columns to datetime (if not already)\n",
    "school_holiday_df['Date'] = pd.to_datetime(school_holiday_df['Date'])\n",
    "final_merged['Date'] = pd.to_datetime(final_merged['Date'], errors='coerce')\n",
    "\n",
    "# 2. Do a left-merge with indicator\n",
    "final_merged = pd.merge(\n",
    "    final_merged,\n",
    "    school_holiday_df[['Date']],    # only need the Date column\n",
    "    on='Date',\n",
    "    how='left',\n",
    "    indicator=True                  # adds a '_merge' column\n",
    ")\n",
    "\n",
    "# 3. Create the flag column (1 if holiday, 0 otherwise)\n",
    "final_merged['Is_School_Holiday'] = (final_merged['_merge'] == 'both').astype(int)\n",
    "\n",
    "# 4. Drop the helper '_merge' column\n",
    "final_merged.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# 5. (Optional) inspect result\n",
    "print(final_merged[['Date', 'Is_School_Holiday']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column for public holiday =1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_holiday_df = pd.read_csv('/home/ms/hfu/ML/ML_Presentation_Workspace/EU_PARK/holidays/baden_wuerttemberg_public_holidays_2022_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_holiday_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_holiday_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Convert both Date columns to datetime (if not already)\n",
    "public_holiday_df['Date'] = pd.to_datetime(school_holiday_df['Date'])\n",
    "final_merged['Date'] = pd.to_datetime(final_merged['Date'], errors='coerce')\n",
    "\n",
    "# 2. Do a left-merge with indicator\n",
    "final_merged = pd.merge(\n",
    "    final_merged,\n",
    "    public_holiday_df[['Date']],    # only need the Date column\n",
    "    on='Date',\n",
    "    how='left',\n",
    "    indicator=True                  # adds a '_merge' column\n",
    ")\n",
    "\n",
    "# 3. Create the flag column (1 if holiday, 0 otherwise)\n",
    "final_merged['Is_Public_Holiday'] = (final_merged['_merge'] == 'both').astype(int)\n",
    "\n",
    "# 4. Drop the helper '_merge' column\n",
    "final_merged.drop(columns=['_merge'], inplace=True)\n",
    "\n",
    "# 5. (Optional) inspect result\n",
    "print(final_merged[['Date', 'Is_Public_Holiday']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.to_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_missing_values(final_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# filepath: /home/ms/hfu/ML/ML_Presentation_Workspace/merge_df.ipynb\n",
    "# Add to a new cell\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example: Histogram for a wait time column (replace with an actual column name)\n",
    "# Identify wait time columns first\n",
    "wait_time_columns = [col for col in final_merged.columns if 'WaitTime' in col]\n",
    "if wait_time_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(final_merged[wait_time_columns[0]].dropna(), kde=True)\n",
    "    plt.title(f'Distribution of {wait_time_columns[0]}')\n",
    "    plt.xlabel('Wait Time')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No wait time columns found to plot.\")\n",
    "\n",
    "\n",
    "# Example: Histogram for Temperature (if 'Temperature' column exists)\n",
    "if 'temperature_in_celsius' in final_merged.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(final_merged['temperature_in_celsius'].dropna(), kde=True)\n",
    "    plt.title('Distribution of Temperature')\n",
    "    plt.xlabel('Temperature')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "elif 'temp_value' in final_merged.columns: # Based on your merge_fn_wind_prec_temp\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(final_merged['temp_value'].dropna(), kde=True)\n",
    "    plt.title('Distribution of Temperature (temp_value)')\n",
    "    plt.xlabel('Temperature')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No 'Temperature' or 'temp_value' column found to plot.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Relationships Between Variables\n",
    "Let's examine how different variables relate to each other, particularly how weather conditions, holidays, and other factors might affect wait times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Select only numerical columns for correlation analysis\n",
    "# First, identify the numeric columns in the dataframe\n",
    "numeric_cols = final_merged.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove unnecessary numeric columns (like index) if they exist\n",
    "exclude_cols = []  # Add columns to exclude if needed\n",
    "numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "# Create a correlation matrix for these numeric columns\n",
    "if numeric_cols:\n",
    "    correlation_matrix = final_merged[numeric_cols].corr(method='pearson', numeric_only=True)\n",
    "    \n",
    "    # Plot the correlation matrix\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title('Correlation Matrix of Numerical Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numerical columns found for correlation analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore relationship between wait time and holidays\n",
    "wait_time_columns = [col for col in final_merged.columns if 'WaitTime' in col]\n",
    "if wait_time_columns and 'Is_School_Holiday' in final_merged.columns:\n",
    "    # Pick a representative wait time column\n",
    "    wait_col = wait_time_columns[0]\n",
    "    \n",
    "    # Filter out values < 0 (probably maintenance or closed)\n",
    "    df_filtered = final_merged[final_merged[wait_col] >= 0].copy()\n",
    "    \n",
    "    # Calculate average wait time on school holidays vs regular days\n",
    "    avg_by_holiday = df_filtered.groupby('Is_School_Holiday')[wait_col].agg(['mean', 'median', 'std']).reset_index()\n",
    "    avg_by_holiday['Is_School_Holiday'] = avg_by_holiday['Is_School_Holiday'].map({0: 'Regular Day', 1: 'School Holiday'})\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Is_School_Holiday', y='mean', data=avg_by_holiday)\n",
    "    plt.title(f'Average {wait_col} by School Holiday Status')\n",
    "    plt.ylabel('Average Wait Time (minutes)')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Wait time statistics by school holiday status:\\n{avg_by_holiday}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore wait time by time of day\n",
    "if wait_time_columns and 'Time' in final_merged.columns:\n",
    "    # Extract hour from time column\n",
    "    df_time = final_merged.copy()\n",
    "    try:\n",
    "        # Try to extract hour directly if Time is already properly formatted\n",
    "        df_time['Hour'] = pd.to_datetime(df_time['Time']).dt.hour\n",
    "    except:\n",
    "        # If that fails, try a different approach assuming 'Time' is a string like '10:30'\n",
    "        df_time['Hour'] = df_time['Time'].str.split(':', expand=True)[0].astype(int)\n",
    "    \n",
    "    # Filter out negative wait times\n",
    "    wait_col = wait_time_columns[0]\n",
    "    df_time = df_time[df_time[wait_col] >= 0]\n",
    "    \n",
    "    # Group by hour and calculate average wait time\n",
    "    hourly_avg = df_time.groupby('Hour')[wait_col].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x='Hour', y=wait_col, data=hourly_avg, marker='o')\n",
    "    plt.title(f'Average {wait_col} by Hour of Day')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Average Wait Time (minutes)')\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the relationship between weather and wait times\n",
    "if wait_time_columns and 'temp_value' in final_merged.columns:\n",
    "    wait_col = wait_time_columns[0]\n",
    "    df_filtered = final_merged[(final_merged[wait_col] >= 0) & (~final_merged['temp_value'].isna())].copy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.scatterplot(x='temp_value', y=wait_col, data=df_filtered, alpha=0.5)\n",
    "    plt.title(f'Relationship Between Temperature and {wait_col}')\n",
    "    plt.xlabel('Temperature (°C)')\n",
    "    plt.ylabel('Wait Time (minutes)')\n",
    "    \n",
    "    # Add a trend line\n",
    "    sns.regplot(x='temp_value', y=wait_col, data=df_filtered, scatter=False, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = df_filtered[['temp_value', wait_col]].corr().iloc[0, 1]\n",
    "    print(f\"Correlation between temperature and {wait_col}: {correlation:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
